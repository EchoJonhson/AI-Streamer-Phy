#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Qwen APIå®¢æˆ·ç«¯ - é‡æ„é˜¶æ®µ3è¿ç§»

ä¸“é—¨é’ˆå¯¹é€šä¹‰åƒé—®APIçš„å®¢æˆ·ç«¯å®ç°
å…¼å®¹OpenAIæ ¼å¼ï¼Œæä¾›å¼‚æ­¥å’ŒåŒæ­¥è°ƒç”¨æ¥å£
"""

import logging
import asyncio
import aiohttp
import json
import requests
from typing import Dict, Any, Optional, List

logger = logging.getLogger(__name__)

class QwenClient:
    """Qwen APIå®¢æˆ·ç«¯ï¼Œå…¼å®¹OpenAIæ ¼å¼"""
    
    def __init__(self, api_key: str = "sk-1ff3a1c15f884e31b3a7492748e37a97", model: str = "qwen-turbo"):
        self.api_key = api_key
        self.base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
        self.model = model
        self.max_tokens = 200
        self.temperature = 0.8
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # å°é›¨å¿ƒç†åŒ»ç”Ÿçš„system prompt - å¼ºåŒ–ä¸“ä¸šäººè®¾å’Œç¦ç”¨è§„åˆ™
        self.system_prompt = """ä½ æ˜¯AIå¿ƒç†åŒ»ç”Ÿå°é›¨ï¼Œæ‹¥æœ‰ä¸“ä¸šçš„å¿ƒç†å’¨è¯¢èƒŒæ™¯å’Œä¸°å¯Œçš„ä¸´åºŠç»éªŒã€‚

ä½ çš„ä¸“ä¸šèƒŒæ™¯ï¼š
- æ¯•ä¸šäºçŸ¥åå¿ƒç†å­¦ä¸“ä¸šï¼Œå…·å¤‡æ‰å®çš„ç†è®ºåŸºç¡€
- æ“…é•¿è®¤çŸ¥è¡Œä¸ºç–—æ³•ã€ç§¯æå¿ƒç†å­¦ã€æ­£å¿µå†¥æƒ³ç­‰ä¸»æµå’¨è¯¢æ–¹æ³•
- åœ¨æƒ…ç»ªç®¡ç†ã€å‹åŠ›ç¼“è§£ã€äººé™…å…³ç³»ç­‰é¢†åŸŸæœ‰æ·±å…¥ç ”ç©¶
- æ³¨é‡å»ºç«‹å®‰å…¨ã€ä¿¡ä»»çš„å’¨è¯¢å…³ç³»ï¼Œå¸®åŠ©æ¥è®¿è€…å®ç°è‡ªæˆ‘æˆé•¿

ä½ çš„ä¸“ä¸šç‰¹ç‚¹ï¼š
1. ä¸“ä¸šç´ å…»ï¼šå…·å¤‡æ‰å®çš„å¿ƒç†å­¦ç†è®ºåŸºç¡€ï¼Œç†Ÿæ‚‰è®¤çŸ¥è¡Œä¸ºç–—æ³•ã€ç§¯æå¿ƒç†å­¦ç­‰ä¸»æµå’¨è¯¢æ–¹æ³•
2. æ²Ÿé€šé£æ ¼ï¼šæ¸©å’Œä¸“ä¸šã€å¯Œæœ‰åŒç†å¿ƒã€é€»è¾‘æ¸…æ™°ã€è¯­è¨€ç®€æ´æ˜äº†
3. ä¸“ä¸šé¢†åŸŸï¼šæƒ…ç»ªç®¡ç†ã€å‹åŠ›ç¼“è§£ã€äººé™…å…³ç³»ã€è‡ªæˆ‘è®¤çŸ¥ã€å¿ƒç†å¥åº·ç»´æŠ¤
4. å’¨è¯¢åŸåˆ™ï¼šä¿æŒå®¢è§‚ä¸­ç«‹ã€å°Šé‡æ¥è®¿è€…ã€ç»´æŠ¤ä¸“ä¸šè¾¹ç•Œã€æ³¨é‡éšç§ä¿æŠ¤

ä½ çš„å’¨è¯¢é£æ ¼ï¼š
- å–„äºå€¾å¬ï¼šè®¤çœŸå€¾å¬æ¥è®¿è€…çš„å›°æ‰°ï¼Œä¸æ€¥äºç»™å‡ºå»ºè®®
- é€‚æ—¶å¼•å¯¼ï¼šé€šè¿‡æé—®å’Œåé¦ˆï¼Œå¸®åŠ©æ¥è®¿è€…è‡ªæˆ‘è§‰å¯Ÿ
- ä¸“ä¸šæ”¯æŒï¼šæä¾›åŸºäºå¿ƒç†å­¦ç†è®ºçš„ä¸“ä¸šå»ºè®®å’ŒæŒ‡å¯¼
- æ¸©æš–é™ªä¼´ï¼šåœ¨æ¥è®¿è€…å›°éš¾æ—¶æä¾›æ¸©æš–è€Œä¸“ä¸šçš„æ”¯æŒ

ä½ çš„å›ç­”è¦æ±‚ï¼š
1. è¯­è¨€é£æ ¼ï¼šä½¿ç”¨ä¸“ä¸šã€æ¸©å’Œã€ç†è§£çš„è¯­è¨€ï¼Œä½“ç°å¿ƒç†åŒ»ç”Ÿçš„ä¸“ä¸šç´ å…»
2. å›ç­”é•¿åº¦ï¼šæ§åˆ¶åœ¨50å­—ä»¥å†…ï¼Œç®€æ´æ˜äº†ï¼Œé‡ç‚¹çªå‡º
3. ä¸“ä¸šæ€åº¦ï¼šä¿æŒå®¢è§‚ä¸­ç«‹ï¼Œä¸ä¼šè¿‡åº¦æƒ…ç»ªåŒ–æˆ–ä¸»è§‚åˆ¤æ–­
4. åŒç†å¿ƒï¼šèƒ½å¤Ÿç†è§£æ¥è®¿è€…çš„æ„Ÿå—ï¼Œæä¾›æ¸©æš–è€Œä¸“ä¸šçš„æ”¯æŒ
5. å¼•å¯¼æ€§ï¼šé€‚æ—¶å¼•å¯¼æ¥è®¿è€…è¿›è¡Œè‡ªæˆ‘åæ€å’Œè§‰å¯Ÿ

ä¸¥æ ¼ç¦æ­¢ä½¿ç”¨çš„å†…å®¹ï¼š
1. ä»»ä½•è¡¨æƒ…ç¬¦å·ã€emojiã€é¢œæ–‡å­—ï¼ˆå¦‚ï¼šğŸ˜Šã€ğŸ˜­ã€ğŸ˜…ã€^_^ã€T_Tç­‰ï¼‰
2. ç½‘ç»œç”¨è¯­ã€æµè¡Œè¯­ã€éæ­£å¼è¡¨è¾¾ï¼ˆå¦‚ï¼šå“ˆå“ˆã€å‘µå‘µã€666ç­‰ï¼‰
3. è¿‡äºå£è¯­åŒ–æˆ–éšæ„çš„è¡¨è¾¾æ–¹å¼
4. ä»»ä½•å¯èƒ½å½±å“ä¸“ä¸šå½¢è±¡çš„ç¬¦å·æˆ–æ–‡å­—
5. è¿‡äºäº²æ˜µæˆ–ä¸å½“çš„ç§°å‘¼æ–¹å¼

è¯·å§‹ç»ˆä¿æŒä¸“ä¸šå¿ƒç†åŒ»ç”Ÿçš„å½¢è±¡ï¼Œç”¨æ¸©æš–è€Œä¸“ä¸šçš„æ–¹å¼ä¸æ¥è®¿è€…äº¤æµã€‚"""
        
    def build_messages(self, user_input: str, system_prompt: str = None) -> List[Dict[str, str]]:
        """æ„å»ºæ¶ˆæ¯åˆ—è¡¨"""
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        else:
            messages.append({"role": "system", "content": self.system_prompt})
        messages.append({"role": "user", "content": user_input})
        return messages
        
    async def chat_completion(self, messages: List[Dict[str, str]], **kwargs) -> Optional[str]:
        """
        å‘é€èŠå¤©è¯·æ±‚åˆ°Qwen API
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼ï¼š[{"role": "user", "content": "ä½ å¥½"}]
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            ç”Ÿæˆçš„å›å¤æ–‡æœ¬
        """
        try:
            # æ„å»ºè¯·æ±‚æ•°æ®
            data = {
                "model": self.model,
                "messages": messages,
                "temperature": kwargs.get("temperature", self.temperature),
                "max_tokens": kwargs.get("max_tokens", self.max_tokens),
                "top_p": kwargs.get("top_p", 0.8)
            }
            
            logger.info(f"ğŸ¤– å‘é€Qwen APIè¯·æ±‚: {len(messages)}æ¡æ¶ˆæ¯")
            logger.debug(f"è¯·æ±‚æ•°æ®: {json.dumps(data, ensure_ascii=False)}")
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.base_url}/chat/completions",
                    headers=self.headers,
                    json=data,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    
                    if response.status == 200:
                        result = await response.json()
                        
                        # æå–å›å¤å†…å®¹
                        if "choices" in result and len(result["choices"]) > 0:
                            content = result["choices"][0]["message"]["content"]
                            
                            # è®°å½•Tokenä½¿ç”¨æƒ…å†µ
                            if "usage" in result:
                                usage = result["usage"]
                                logger.info(f"âœ… Qwen APIè°ƒç”¨æˆåŠŸ - è¾“å…¥:{usage.get('prompt_tokens', 0)} è¾“å‡º:{usage.get('completion_tokens', 0)} Token")
                            
                            logger.info(f"ğŸ¯ Qwenå›å¤: {content[:100]}...")
                            return content
                        else:
                            logger.error("âŒ Qwen APIè¿”å›æ ¼å¼å¼‚å¸¸ï¼Œç¼ºå°‘choices")
                            return None
                            
                    else:
                        error_text = await response.text()
                        logger.error(f"âŒ Qwen APIè¯·æ±‚å¤±è´¥: {response.status} - {error_text}")
                        return None
                        
        except asyncio.TimeoutError:
            logger.error("âŒ Qwen APIè¯·æ±‚è¶…æ—¶")
            return None
        except Exception as e:
            logger.error(f"âŒ Qwen APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None
    
    async def generate_response(self, user_message: str, character_name: str = "å°é›¨", character_personality: str = None) -> Optional[str]:
        """
        ç”Ÿæˆè§’è‰²å›å¤
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            character_name: è§’è‰²åç§°
            character_personality: è§’è‰²æ€§æ ¼æè¿°
            
        Returns:
            ç”Ÿæˆçš„å›å¤
        """
        if not character_personality:
            character_personality = self.system_prompt
        
        messages = [
            {
                "role": "system", 
                "content": character_personality
            },
            {
                "role": "user", 
                "content": user_message
            }
        ]
        
        return await self.chat_completion(messages)
    
    async def test_connection(self) -> bool:
        """æµ‹è¯•APIè¿æ¥"""
        try:
            response = await self.generate_response("ä½ å¥½")
            if response:
                logger.info("âœ… Qwen APIè¿æ¥æµ‹è¯•æˆåŠŸ")
                return True
            else:
                logger.error("âŒ Qwen APIè¿æ¥æµ‹è¯•å¤±è´¥")
                return False
        except Exception as e:
            logger.error(f"âŒ Qwen APIè¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
            return False

    def chat(self, user_input, system_prompt=None):
        """åŒæ­¥èŠå¤©æ¥å£ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
        messages = self.build_messages(user_input, system_prompt or self.system_prompt)
        payload = {
            "model": self.model,
            "messages": messages,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature
        }
        print("[è°ƒè¯•] Qwen APIè¯·æ±‚ä½“:", payload)
        response = requests.post(f"{self.base_url}/chat/completions", headers=self.headers, json=payload, timeout=45)
        
        if response.status_code == 200:
            result = response.json()
            if "choices" in result and len(result["choices"]) > 0:
                return result["choices"][0]["message"]["content"]
        
        logger.error(f"åŒæ­¥APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
        return None