#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¢„è®­ç»ƒSoVITS TTSç®¡ç†å™¨ - ç›´æ¥ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
"""

import asyncio
import logging
import json
import os
import sys
from pathlib import Path
from typing import Dict, Any, Optional, Tuple
import numpy as np
import torch

logger = logging.getLogger(__name__)

class PretrainedSoVITSTTS:
    """é¢„è®­ç»ƒSoVITS TTSç®¡ç†å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.sovits_config = config.get('sovits', {})
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
        self.use_pretrained = self.sovits_config.get('use_pretrained', False)
        
        if not self.use_pretrained:
            logger.warning("æœªå¯ç”¨é¢„è®­ç»ƒæ¨¡å¼ï¼Œè¯·åœ¨config.yamlä¸­è®¾ç½®use_pretrained: true")
            return
            
        # é¢„è®­ç»ƒæ¨¡å‹é…ç½®
        self.pretrained_config = self.sovits_config.get('pretrained_models', {})
        self.gpt_weights_path = self.pretrained_config.get('gpt_weights_path', '')
        self.sovits_weights_path = self.pretrained_config.get('sovits_weights_path', '')
        self.model_version = self.pretrained_config.get('version', 'v2')
        
        # å‚è€ƒéŸ³é¢‘é…ç½®
        self.ref_config = self.sovits_config.get('reference_audio', {})
        self.ref_audio_path = self.ref_config.get('ref_audio_path', '')
        self.prompt_text = self.ref_config.get('prompt_text', '')
        self.prompt_lang = self.ref_config.get('prompt_lang', 'zh')
        
        # æ¨ç†å‚æ•°
        self.inference_config = self.sovits_config.get('inference', {})
        self.temperature = self.inference_config.get('temperature', 0.6)
        self.top_p = self.inference_config.get('top_p', 0.9)
        self.top_k = self.inference_config.get('top_k', 5)
        self.speed = self.inference_config.get('speed', 1.0)
        self.text_lang = self.inference_config.get('text_lang', 'zh')
        self.sample_steps = self.inference_config.get('sample_steps', 32)
        self.super_sampling = self.inference_config.get('super_sampling', False)
        
        # TTSæ¨¡å‹å®ä¾‹
        self.tts_model = None
        self.is_initialized = False
        
        # çŠ¶æ€ä¿¡æ¯
        self.status = {
            'initialized': False,
            'model_loaded': False,
            'gpt_model_path': self.gpt_weights_path,
            'sovits_model_path': self.sovits_weights_path,
            'version': self.model_version,
            'error': None
        }
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._initialize_model()
    
    def _initialize_model(self):
        """åˆå§‹åŒ–é¢„è®­ç»ƒæ¨¡å‹"""
        try:
            logger.info("ğŸš€ åˆå§‹åŒ–é¢„è®­ç»ƒSoVITSæ¨¡å‹...")
            
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not self._check_model_files():
                return False
            
            # æ·»åŠ GPT-SoVITSè·¯å¾„åˆ°sys.path
            sovits_path = Path(self.sovits_config.get('sovits_path', 'GPT-SoVITS'))
            if sovits_path.exists():
                sys.path.insert(0, str(sovits_path))
                sys.path.insert(0, str(sovits_path / 'GPT_SoVITS'))
            
            # å¯¼å…¥GPT-SoVITSæ¨¡å—
            from TTS_infer_pack.TTS import TTS, TTS_Config
            
            # åˆ›å»ºè‡ªå®šä¹‰é…ç½® - ä½¿ç”¨ç»å¯¹è·¯å¾„
            custom_config = {
                "device": "cpu",
                "is_half": False, 
                "version": self.model_version,
                "t2s_weights_path": self.gpt_weights_path,
                "vits_weights_path": self.sovits_weights_path,
                "cnhuhbert_base_path": "C:/Users/MSIK/Desktop/ChatBot/aistreamer/GPT-SoVITS/GPT_SoVITS/pretrained_models/chinese-hubert-base",
                "bert_base_path": "C:/Users/MSIK/Desktop/ChatBot/aistreamer/GPT-SoVITS/GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large",
            }
            
            # åˆå§‹åŒ–TTSæ¨¡å‹
            logger.info(f"ğŸ“¦ åŠ è½½æ¨¡å‹: GPT={Path(self.gpt_weights_path).name}, SoVITS={Path(self.sovits_weights_path).name}")
            
            tts_config = TTS_Config({"custom": custom_config})
            self.tts_model = TTS(tts_config)
            
            self.is_initialized = True
            self.status.update({
                'initialized': True,
                'model_loaded': True,
                'error': None
            })
            
            logger.info("âœ… é¢„è®­ç»ƒSoVITSæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            logger.info(f"ğŸ­ æ¨¡å‹ç‰ˆæœ¬: {self.model_version}")
            logger.info(f"ğŸ“„ GPTæ¨¡å‹: {Path(self.gpt_weights_path).name}")
            logger.info(f"ğŸµ SoVITSæ¨¡å‹: {Path(self.sovits_weights_path).name}")
            
            return True
            
        except Exception as e:
            error_msg = f"é¢„è®­ç»ƒæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}"
            logger.error(error_msg)
            self.status.update({
                'initialized': False,
                'model_loaded': False,
                'error': error_msg
            })
            return False
    
    def _check_model_files(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        if not self.gpt_weights_path or not self.sovits_weights_path:
            logger.error("âŒ æ¨¡å‹è·¯å¾„æœªé…ç½®")
            return False
        
        gpt_path = Path(self.gpt_weights_path)
        sovits_path = Path(self.sovits_weights_path)
        
        if not gpt_path.exists():
            logger.error(f"âŒ GPTæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {gpt_path}")
            return False
            
        if not sovits_path.exists():
            logger.error(f"âŒ SoVITSæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {sovits_path}")
            return False
        
        logger.info(f"âœ… æ¨¡å‹æ–‡ä»¶æ£€æŸ¥é€šè¿‡")
        logger.info(f"  GPTæ¨¡å‹: {gpt_path} ({gpt_path.stat().st_size / 1024 / 1024:.1f}MB)")
        logger.info(f"  SoVITSæ¨¡å‹: {sovits_path} ({sovits_path.stat().st_size / 1024 / 1024:.1f}MB)")
        
        return True
    
    async def synthesize(self, text: str, ref_audio_path: str = None, prompt_text: str = None) -> Optional[Tuple[int, np.ndarray]]:
        """åˆæˆè¯­éŸ³
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            ref_audio_path: å‚è€ƒéŸ³é¢‘è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            prompt_text: å‚è€ƒéŸ³é¢‘å¯¹åº”æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            (é‡‡æ ·ç‡, éŸ³é¢‘æ•°æ®)å…ƒç»„ï¼Œå¤±è´¥è¿”å›None
        """
        if not self.is_initialized:
            logger.error("âŒ æ¨¡å‹æœªåˆå§‹åŒ–")
            return None
        
        if not text or not text.strip():
            logger.warning("æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡åˆæˆ")
            return None
        
        try:
            text = text.strip()
            
            # ä½¿ç”¨é…ç½®ä¸­çš„å‚è€ƒéŸ³é¢‘æˆ–ä¼ å…¥çš„å‚è€ƒéŸ³é¢‘
            ref_audio = ref_audio_path or self.ref_audio_path
            prompt = prompt_text or self.prompt_text
            
            if not ref_audio:
                logger.warning("âš ï¸ æœªè®¾ç½®å‚è€ƒéŸ³é¢‘ï¼Œå°†ä½¿ç”¨é»˜è®¤è®¾ç½®")
                # å¯ä»¥è®¾ç½®ä¸€ä¸ªé»˜è®¤çš„å‚è€ƒéŸ³é¢‘
                ref_audio = ""
            
            # æ„å»ºæ¨ç†å‚æ•°
            inputs = {
                "text": text,
                "text_lang": self.text_lang,
                "ref_audio_path": ref_audio,
                "prompt_text": prompt,
                "prompt_lang": self.prompt_lang,
                "top_k": self.top_k,
                "top_p": self.top_p,
                "temperature": self.temperature,
                "text_split_method": "cut5",
                "batch_size": 1,
                "speed_factor": self.speed,
                "seed": -1,
                "parallel_infer": True,
                "repetition_penalty": 1.35,
                "sample_steps": self.sample_steps,
                "super_sampling": self.super_sampling,
            }
            
            logger.info(f"ğŸµ å¼€å§‹åˆæˆè¯­éŸ³: {text[:50]}...")
            
            # æ‰§è¡Œæ¨ç†
            sr, audio_data = self.tts_model.run(inputs)
            
            if audio_data is not None:
                logger.info(f"âœ… è¯­éŸ³åˆæˆæˆåŠŸ: {len(audio_data)/sr:.2f}ç§’")
                return sr, audio_data
            else:
                logger.error("âŒ è¯­éŸ³åˆæˆå¤±è´¥ï¼šè¿”å›æ•°æ®ä¸ºç©º")
                return None
                
        except Exception as e:
            logger.error(f"è¯­éŸ³åˆæˆå¼‚å¸¸: {e}")
            return None
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–TTSçŠ¶æ€"""
        return {
            "provider": "pretrained_sovits",
            "initialized": self.is_initialized,
            "use_pretrained": self.use_pretrained,
            "model_info": {
                "gpt_model": Path(self.gpt_weights_path).name if self.gpt_weights_path else "æœªè®¾ç½®",
                "sovits_model": Path(self.sovits_weights_path).name if self.sovits_weights_path else "æœªè®¾ç½®",
                "version": self.model_version,
            },
            "reference_audio": {
                "path": self.ref_audio_path,
                "prompt_text": self.prompt_text,
                "prompt_lang": self.prompt_lang,
            },
            "inference_params": {
                "temperature": self.temperature,
                "top_p": self.top_p,
                "top_k": self.top_k,
                "speed": self.speed,
                "text_lang": self.text_lang,
                "sample_steps": self.sample_steps,
                "super_sampling": self.super_sampling,
            },
            "status": self.status
        }
    
    def set_reference_audio(self, ref_audio_path: str, prompt_text: str = "", prompt_lang: str = "zh"):
        """è®¾ç½®å‚è€ƒéŸ³é¢‘"""
        self.ref_audio_path = ref_audio_path
        self.prompt_text = prompt_text
        self.prompt_lang = prompt_lang
        logger.info(f"ğŸ¤ è®¾ç½®å‚è€ƒéŸ³é¢‘: {Path(ref_audio_path).name}")
    
    def update_inference_params(self, **kwargs):
        """æ›´æ–°æ¨ç†å‚æ•°"""
        for key, value in kwargs.items():
            if hasattr(self, key):
                setattr(self, key, value)
                logger.info(f"ğŸ”§ æ›´æ–°å‚æ•° {key} = {value}")
    
    def list_available_models(self) -> Dict[str, list]:
        """åˆ—å‡ºå¯ç”¨çš„æ¨¡å‹æ–‡ä»¶"""
        gpt_models = []
        sovits_models = []
        
        # æ‰«æGPTæ¨¡å‹æ–‡ä»¶å¤¹
        gpt_dir = Path("audio_files/ä¸­é…æ•°æ®é›†åˆ¶/GPT_weights_v2")
        if gpt_dir.exists():
            for file in gpt_dir.glob("*.ckpt"):
                gpt_models.append({
                    "name": file.name,
                    "path": str(file),
                    "size_mb": file.stat().st_size / 1024 / 1024
                })
        
        # æ‰«æSoVITSæ¨¡å‹æ–‡ä»¶å¤¹  
        sovits_dir = Path("audio_files/ä¸­é…æ•°æ®é›†åˆ¶/SoVITS_weights_v2")
        if sovits_dir.exists():
            for file in sovits_dir.glob("*.pth"):
                sovits_models.append({
                    "name": file.name,
                    "path": str(file),
                    "size_mb": file.stat().st_size / 1024 / 1024
                })
        
        return {
            "gpt_models": gpt_models,
            "sovits_models": sovits_models
        } 