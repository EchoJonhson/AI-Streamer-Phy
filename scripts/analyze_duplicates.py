#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡å¤æ–‡ä»¶åˆ†æè„šæœ¬ - å¿«é€Ÿè¯„ä¼°æ¸…ç†å®‰å…¨æ€§
"""

import os
import difflib
from pathlib import Path

def analyze_file_similarity(src_file, backend_file):
    """åˆ†ææ–‡ä»¶ç›¸ä¼¼åº¦"""
    try:
        with open(src_file, 'r', encoding='utf-8') as f:
            src_content = f.read()
        with open(backend_file, 'r', encoding='utf-8') as f:
            backend_content = f.read()
        
        matcher = difflib.SequenceMatcher(None, src_content, backend_content)
        similarity = matcher.ratio()
        
        src_lines = len(src_content.splitlines())
        backend_lines = len(backend_content.splitlines())
        
        return {
            "similarity": similarity,
            "src_lines": src_lines,
            "backend_lines": backend_lines,
            "identical": similarity > 0.99,
            "nearly_identical": similarity > 0.95,
            "similar": similarity > 0.80
        }
    except Exception as e:
        return {"error": str(e)}

def main():
    project_root = Path(__file__).parent.parent
    src_dir = project_root / "src" / "open_llm_vtuber"
    backend_dir = project_root / "backend"
    
    # æ–‡ä»¶æ˜ å°„å…³ç³»
    file_mappings = {
        "config.py": "core/config.py",
        "chat_history.py": "ai/chat_history.py",
        "llm_manager.py": "ai/llm_manager.py",
        "qwen_client.py": "ai/qwen_client.py",
        "tts_manager.py": "voice/tts_manager.py",
        "sovits_inference_engine.py": "voice/sovits_inference_engine.py",
        "server.py": "core/server.py",
        "routes.py": "core/routes.py",
        "websocket_handler.py": "core/websocket_handler.py",
        "asr_manager.py": "voice/asr_manager.py",
        "llm_api.py": "ai/llm_api.py",
        "premium_tts.py": "voice/premium_tts.py",
        "sovits_tts.py": "voice/sovits_tts.py",
        "voice_api.py": "voice/voice_api.py",
    }
    
    print("ğŸ“Š é‡å¤æ–‡ä»¶ç›¸ä¼¼åº¦åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    
    safe_to_remove = []
    needs_review = []
    
    for src_filename, backend_path in file_mappings.items():
        src_file = src_dir / src_filename
        backend_file = backend_dir / backend_path
        
        if src_file.exists() and backend_file.exists():
            analysis = analyze_file_similarity(src_file, backend_file)
            
            if "error" in analysis:
                print(f"âŒ {src_filename}: {analysis['error']}")
                continue
            
            similarity = analysis["similarity"]
            status = ""
            
            if analysis["identical"]:
                status = "ğŸŸ¢ ç›¸åŒ"
                safe_to_remove.append(src_filename)
            elif analysis["nearly_identical"]:
                status = "ğŸŸ¡ å‡ ä¹ç›¸åŒ"
                safe_to_remove.append(src_filename)
            elif analysis["similar"]:
                status = "ğŸŸ  ç›¸ä¼¼"
                needs_review.append(src_filename)
            else:
                status = "ğŸ”´ å·®å¼‚è¾ƒå¤§"
                needs_review.append(src_filename)
            
            print(f"{status} {src_filename}: {similarity:.1%} ç›¸ä¼¼åº¦ ({analysis['src_lines']} -> {analysis['backend_lines']} è¡Œ)")
        else:
            if not src_file.exists():
                print(f"âšª {src_filename}: srcæ–‡ä»¶ä¸å­˜åœ¨")
            if not backend_file.exists():
                print(f"âšª {src_filename}: backendæ–‡ä»¶ä¸å­˜åœ¨")
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ¸…ç†å»ºè®®:")
    print(f"ğŸŸ¢ å®‰å…¨åˆ é™¤ ({len(safe_to_remove)} ä¸ª): {', '.join(safe_to_remove)}")
    print(f"ğŸŸ  éœ€è¦å®¡æŸ¥ ({len(needs_review)} ä¸ª): {', '.join(needs_review)}")

if __name__ == "__main__":
    main()